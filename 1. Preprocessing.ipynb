{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "830b5916-ae02-4b86-9ad9-a972b7b452dd",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f032f4-c10a-4946-b870-2fbcd540af55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pywt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import butter, lfilter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3a15dd-971e-4d4f-b1ac-05c8555c592c",
   "metadata": {},
   "source": [
    "Menampilkan salah satu data yang digunakan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7c0486-8f29-47b8-abb5-eaeaa546e506",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Raw_Data_EEG/P02_SHAFATYRA.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35df141-6946-44b4-99c7-b793f158d6fc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if 'AUX' in data.columns:\n",
    "    data = data.drop(columns=['AUX'])\n",
    "    \n",
    "# Convert 'Timestamp' column to datetime and set as index\n",
    "if 'Timestamp' in data.columns:  \n",
    "    data['Timestamp'] = pd.to_datetime(data['Timestamp'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85c2c72-a7ec-40a4-b7bb-d893368acc96",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fungsi untuk memplot sinyal mentah dengan subplot per channel\n",
    "def plot_data(df, channels, title):\n",
    "    plt.figure(figsize=(12, len(channels) * 3))  \n",
    "    for i, channel in enumerate(channels):\n",
    "        plt.subplot(len(channels), 1, i + 1) \n",
    "        plt.plot(df.index, df[channel], label=channel)\n",
    "        plt.title(f'{channel} - {title}')\n",
    "        plt.xlabel('Timestamp')\n",
    "        plt.ylabel('Amplitude')\n",
    "    plt.tight_layout()  # Mengatur layout agar tidak overlap\n",
    "    plt.show()\n",
    "\n",
    "channels = ['TP9', 'AF7','AF8', 'TP10']\n",
    "plot_data(data, channels, 'Sinyal EEG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3aa0e0b-ea46-41c7-a5b8-16173de8a442",
   "metadata": {},
   "outputs": [],
   "source": [
    "directories = [\"1. Split\", \"2. Cleaning\", \"3. Augmentasi\", \"4. Average\", \n",
    "               \"5. Transform\",\"6. Label\", \"7.1. FFT_Plot\", \"7.2. DWT_Plot\"]\n",
    "for directory in directories:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "raw_dir = \"Raw_Data_EEG\"\n",
    "split_dir = \"1. Split\"\n",
    "cleaning_dir = \"2. Cleaning\"\n",
    "augmentasi_dir = \"3. Augmentasi\"\n",
    "average_dir = \"4. Average\"\n",
    "Transform_dir = \"5. Transform\"\n",
    "label_dir = \"6. Label\"\n",
    "FFT_Plot_dir = \"7.1. FFT_Plot\"\n",
    "DWT_Plot_dir = \"7.2. DWT_Plot\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1d0f57-9b0e-4e3a-a3b3-5617a041757f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424e8dea-af25-4831-aa7f-e577adb09d1f",
   "metadata": {},
   "source": [
    "Memisahkan data berdasarkan aktivitas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacfec4b-9762-42de-a2b4-1f1947de6cdf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_data(file_path, file_number):\n",
    "    df = pd.read_csv(file_path)\n",
    "    if 'AUX' in df.columns:\n",
    "        df = df.drop(columns=['AUX'])\n",
    "    if 'Timestamp' in df.columns:    \n",
    "        df['Timestamp'] = pd.to_datetime(df['Timestamp'], errors='coerce')\n",
    "        start_times = [\n",
    "            df['Timestamp'].iloc[0],\n",
    "            df['Timestamp'].iloc[0] + pd.Timedelta(minutes=5),\n",
    "            df['Timestamp'].iloc[0] + pd.Timedelta(minutes=35),\n",
    "            df['Timestamp'].iloc[0] + pd.Timedelta(minutes=43),\n",
    "            df['Timestamp'].iloc[0] + pd.Timedelta(minutes=50)]\n",
    "        end_times = [\n",
    "            df['Timestamp'].iloc[0] + pd.Timedelta(minutes=5),\n",
    "            df['Timestamp'].iloc[0] + pd.Timedelta(minutes=35),\n",
    "            df['Timestamp'].iloc[0] + pd.Timedelta(minutes=43),\n",
    "            df['Timestamp'].iloc[0] + pd.Timedelta(minutes=50),\n",
    "            df['Timestamp'].iloc[0] + pd.Timedelta(minutes=51)]\n",
    "        csv_files = [\n",
    "            df[(df['Timestamp'] >= start_times[i]) & (df['Timestamp'] <= end_times[i])]\n",
    "            for i in range(5)]\n",
    "        for i, csv_file in enumerate(csv_files):\n",
    "            filename = f'{split_dir}/{file_number}_K{i}.csv'\n",
    "            csv_file.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96600a5-5b05-4758-b26d-ac9f01489ecd",
   "metadata": {},
   "source": [
    "Referensi implementasi filter bandpass Butterworth:\n",
    "- https://medium.com/time-series-ml/dsp-frequency-bandpass-filter-in-python-62c0e7189852\n",
    "- https://docs.scipy.org/doc/scipy-1.9.0/reference/generated/scipy.signal.butter.html\n",
    "- https://www.machinelearningplus.com/machine-learning/how-to-detect-outliers-with-z-score/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba684d10-b448-47ec-8f23-e3ea3b306112",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Butter Band-pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ac554a-d026-4c14-aac0-e8bfb0404ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc774002-4bb1-4b1f-859d-606f8d8c4cd0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Modified Z-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26994f15-f5cc-4aec-ba11-7491bf8d8b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modified_z_score(data, k=0.33725):\n",
    "    median = np.median(data)\n",
    "    mad = np.median(np.abs(data - median))\n",
    "    if mad == 0:\n",
    "        return np.zeros_like(data)\n",
    "    z_scores = k * (data - median) / mad\n",
    "    return z_scores\n",
    "\n",
    "def remove_artifacts(df, threshold=3.5):\n",
    "    for column in df.columns:\n",
    "        data = df[column].values\n",
    "        z_scores = modified_z_score(data)\n",
    "        data[np.abs(z_scores) > threshold] = np.nan\n",
    "        df[column] = pd.Series(data).interpolate().values\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192c0c67-eeea-437f-a115-960f117d93fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d698a093-744e-4f05-bd16-6558d7b8368c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_data(df, desired_length=1000):\n",
    "    current_length = len(df)\n",
    "    if current_length < desired_length:\n",
    "        padding_length = desired_length - current_length\n",
    "        padding_values = np.zeros((padding_length, len(df.columns)))\n",
    "        padding_df = pd.DataFrame(padding_values, columns=df.columns)\n",
    "        df = pd.concat([df, padding_df], ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661bfb98-425c-48fa-a346-57d8952cc140",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Augmentasi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff971f1-c23f-45ec-983c-15be13124434",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def augment_eeg_data(eeg_data):\n",
    "    augmented_data = eeg_data + np.random.normal(0, 0.1, eeg_data.shape)\n",
    "    return augmented_data\n",
    "\n",
    "def write_augmented_eeg_data(file_path, augmented_eeg_data):\n",
    "    df = pd.DataFrame(augmented_eeg_data, columns=['TP9', 'AF7', 'AF8', 'TP10'])\n",
    "    df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e8a48f-e331-4513-b2e8-2625334d2a6b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be96237-d39a-48d9-a682-4d8ffa100865",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def average_eeg_data(data):\n",
    "    required_columns = ['TP9', 'AF7', 'AF8', 'TP10']\n",
    "    if not all(column in data.columns for column in required_columns):\n",
    "        raise ValueError(f\"CSV file {file_name} must contain the following columns: {required_columns}\")\n",
    "    data['Average'] = data[required_columns].mean(axis=1)\n",
    "    average_data = data[['Average']]\n",
    "    return average_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cb3ddf-8d65-4006-a70f-b4d3e8b1cbef",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Main cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a117b20-ecbd-423d-b87a-9807ed26afa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowcut = 8\n",
    "highcut = 40\n",
    "fs = 256\n",
    "\n",
    "files = [f for f in os.listdir(raw_dir) if f.endswith('.csv')]\n",
    "for i, file_name in enumerate(files):\n",
    "    file_path = os.path.join(raw_dir, file_name)\n",
    "    split_data(file_path, i+1)\n",
    "print(\"Split selesai\")\n",
    "\n",
    "files = [f for f in os.listdir(split_dir) if f.endswith('.csv')]\n",
    "for file_name in files:\n",
    "    file_path = os.path.join(split_dir, file_name)\n",
    "    df = pd.read_csv(file_path)\n",
    "    df.set_index('Timestamp', inplace=True)\n",
    "    for column in df.columns:\n",
    "        df[column] = butter_bandpass_filter(df[column].values, lowcut, highcut, fs) #Butter Band Pass\n",
    "    df = remove_artifacts(df) # remove artifact\n",
    "    df = padding_data(df) # padding data\n",
    "    filename, _ = os.path.splitext(os.path.basename(file_path))\n",
    "    output_file_path = os.path.join(cleaning_dir, f\"{filename}.csv\")\n",
    "    df.to_csv(output_file_path, index=False)\n",
    "print('Cleaning selesai')\n",
    "\n",
    "files = [f for f in os.listdir(cleaning_dir) if f.endswith('.csv')]\n",
    "for file_name in files:\n",
    "    file_path = os.path.join(cleaning_dir, file_name)\n",
    "    df = pd.read_csv(file_path)\n",
    "    for i in range(10):\n",
    "        augmented_eeg_data = augment_eeg_data(df)\n",
    "        output_file_path = os.path.join(augmentasi_dir, f\"{i}_{file_name}\")\n",
    "        write_augmented_eeg_data(output_file_path, augmented_eeg_data)\n",
    "print('augmentasi selesai')\n",
    "\n",
    "files = [f for f in os.listdir(augmentasi_dir) if f.endswith('.csv')]\n",
    "for file_name in files:\n",
    "    file_path = os.path.join(augmentasi_dir, file_name)\n",
    "    df = pd.read_csv(file_path)\n",
    "    average_data = average_eeg_data(df)\n",
    "    output_file_path = os.path.join(average_dir, file_name)\n",
    "    average_data.to_csv(output_file_path, index=False)\n",
    "print('average selesai')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d84b710-a998-40b9-a982-29b81b79cd83",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Transformasi Signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b7dd4f-c5a7-4cdb-8c6e-12d5c9606279",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Fast Fourier Transform (FFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9444ea33-304b-466b-8ad8-9c6d94cf6528",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_power_spectrum(xn, fs=256):\n",
    "    N = len(xn)\n",
    "    Xk = (1 / (fs * N)) * np.abs(np.fft.fft(xn)) ** 2\n",
    "    Xk = Xk[:(N // 2) + 1]\n",
    "    Xk[1:-1] = 2 * Xk[1:-1]\n",
    "    return Xk\n",
    "\n",
    "def fft(data, fs=256):\n",
    "    freqs = None\n",
    "    N = None\n",
    "    channel_name = 'Average'\n",
    "    xn = data[channel_name].values\n",
    "    if N is None:\n",
    "        N = len(xn)\n",
    "        k = np.arange(N // 2 + 1)\n",
    "        freqs = k * fs / N\n",
    "    else:\n",
    "        if len(xn) > N:\n",
    "            xn = xn[:N]\n",
    "        elif len(xn) < N:\n",
    "            xn = np.pad(xn, (0, N - len(xn)), 'constant')\n",
    "    power_spectrum_data = compute_power_spectrum(xn, fs)\n",
    "    file_results = pd.DataFrame([power_spectrum_data], columns=freqs)\n",
    "    file_results.insert(0, 'File Name', file_name)\n",
    "    return file_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dd4e8f-b93c-4de8-9537-69c9b668f95e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Discrete Wavelet Transform (DWT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030b403e-3f96-429c-9814-6186a178a8e2",
   "metadata": {},
   "source": [
    "https://pywavelets.readthedocs.io/en/latest/ref/dwt-discrete-wavelet-transform.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450fb2c0-16e4-42ce-9f9e-f45175fbb374",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dwt(data, wavelet='db4'):\n",
    "    data = data.values\n",
    "    coeffs = pywt.wavedec(data, wavelet)\n",
    "    approximation = coeffs[0]\n",
    "    details = coeffs[1:]\n",
    "    approximation_df = pd.DataFrame(approximation, columns=['Approximation']).T\n",
    "    detail_dfs = [pd.DataFrame(detail, columns=[f'Detail_Level_{i}']).T for i, detail in enumerate(details, start=1)]\n",
    "    details_combined_df = pd.concat(detail_dfs, ignore_index=True)\n",
    "    final_df = pd.concat([approximation_df, details_combined_df], axis=0).reset_index(drop=True)\n",
    "    file_results = final_df.mean()\n",
    "    file_results = pd.DataFrame(file_results).T\n",
    "    return file_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a12a3ac-c039-4600-beaf-d58a03f1fa10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# FFT\n",
    "combined_results = pd.DataFrame()\n",
    "files = [f for f in os.listdir(average_dir) if f.endswith('.csv')]\n",
    "for file_name in files:\n",
    "    file_path = os.path.join(average_dir, file_name)\n",
    "    df = pd.read_csv(file_path)\n",
    "    file_results = fft(df)\n",
    "    combined_results = pd.concat([combined_results, file_results], ignore_index=True)\n",
    "output_file_path = os.path.join(Transform_dir, \"FFT_Transform.csv\")\n",
    "combined_results.to_csv(output_file_path, index=False)\n",
    "\n",
    "# DWT\n",
    "combined_results = pd.DataFrame()\n",
    "files = [f for f in os.listdir(average_dir) if f.endswith('.csv')]\n",
    "for file_name in files:\n",
    "    file_path = os.path.join(average_dir, file_name)\n",
    "    df = pd.read_csv(file_path)\n",
    "    file_results = dwt(df['Average'])\n",
    "    combined_results = pd.concat([combined_results, file_results], ignore_index=True)\n",
    "    if 'File Name' not in combined_results.columns:\n",
    "        combined_results.insert(0, 'File Name', file_name)\n",
    "    else:\n",
    "        combined_results['File Name'].iloc[-len(file_results):] = file_name\n",
    "output_file_path = os.path.join(Transform_dir, \"DWT_Transform.csv\")\n",
    "combined_results.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e239d85-c290-4822-8419-b5abc2766e6e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d501e86a-6fb5-4090-b3b5-754c1bc0a8b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_theta_beta_ratio(data, theta_range=(4, 8), beta_range=(13, 30)):\n",
    "        freqs = df_fft.columns[1:].astype(float)\n",
    "        psd_values = data[1:].values.astype(float)\n",
    "        theta_power = np.mean(psd_values[(freqs >= theta_range[0]) & (freqs <= theta_range[1])])\n",
    "        beta_power = np.mean(psd_values[(freqs >= beta_range[0]) & (freqs <= beta_range[1])])\n",
    "        theta_beta_ratio = theta_power / beta_power\n",
    "        return theta_beta_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fa4260-7879-4bff-864e-77c9e26cf068",
   "metadata": {
    "tags": []
   },
   "source": [
    "### FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e789497e-4e9b-48e0-b05e-f7574ea65e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('5. Transform/FFT_Transform.csv')\n",
    "df_fft = df.iloc[:,1:]\n",
    "df_fft['Theta/Beta Ratio'] = df_fft.apply(calculate_theta_beta_ratio, axis=1)\n",
    "kmeans = KMeans(n_clusters=4, random_state=42).fit(df_fft['Theta/Beta Ratio'].values.reshape(-1, 1))\n",
    "centroids = kmeans.cluster_centers_.flatten()\n",
    "labels = kmeans.labels_\n",
    "new_labels = np.zeros_like(labels)\n",
    "new_labels[labels == 0] = 0\n",
    "new_labels[labels == 1] = 2\n",
    "new_labels[labels == 2] = 3\n",
    "new_labels[labels == 3] = 1\n",
    "df_fft['Stress Level'] = new_labels\n",
    "df_new = df_fft.drop(columns='Theta/Beta Ratio')\n",
    "df_new['File Name'] = df['File Name']\n",
    "df_new.to_csv('6. Label/FFT_Labeled.csv', index=False)\n",
    "print('Data berhasil disimpan.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0082e871-8feb-4e0d-a631-bbe555caa88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fft['Stress Level'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ddb738-a13d-4ca6-9943-6b316dcf3a8c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### DWT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d091831-f04d-4cf9-a50d-901b0a352017",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dwt = pd.read_csv('5. Transform/DWT_Transform.csv')\n",
    "df_fft = pd.read_csv('6. Label/FFT_Labeled.csv')\n",
    "df = df_dwt.copy()\n",
    "df['Stress Level'] = df_fft['Stress Level']\n",
    "df.to_csv('6. Label/DWT_Labeled.csv', index=False)\n",
    "print('Data berhasil disimpan.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22761fc-75a1-45b3-89be-48b3cb5f50a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Stress Level'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfb6955-8ab5-49c1-ae5f-7fd7b418808c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Ploting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1dc831-8f2d-41b6-b9f6-732513db18b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### FFT Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b40410-71ff-47f4-9eb1-33d2658cbae0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_color_for_frequency(frequency):\n",
    "    if 0 <= frequency < 4:\n",
    "        return color_map['delta']\n",
    "    elif 4 <= frequency < 8:\n",
    "        return color_map['theta']\n",
    "    elif 8 <= frequency < 12:\n",
    "        return color_map['alpha']\n",
    "    elif 12 <= frequency < 35:\n",
    "        return color_map['beta']\n",
    "    elif frequency >= 35:\n",
    "        return color_map['gamma']\n",
    "    else:\n",
    "        return 'lightblue'\n",
    "\n",
    "file_path = '6. Label/FFT_Labeled.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "os.makedirs(FFT_Plot_dir, exist_ok=True)\n",
    "y_min = df.iloc[:, :-2].quantile(0.01).min()\n",
    "y_max = df.iloc[:, :-2].quantile(0.99).max()\n",
    "x_min = float(df.columns[0])\n",
    "x_max = float(df.columns[-3])\n",
    "color_map = {\n",
    "    'delta': 'blue',\n",
    "    'theta': 'green',\n",
    "    'alpha': 'red',\n",
    "    'beta': 'orange',\n",
    "    'gamma': 'purple'\n",
    "}\n",
    "for index, row in df.iterrows():\n",
    "    x_values = df.columns[:-2].astype(float)\n",
    "    y_values = row.values[:-2]\n",
    "    colors = [get_color_for_frequency(freq) for freq in x_values]\n",
    "    plt.plot(x_values, y_values, color='black', linewidth=1.5)\n",
    "    for i in range(len(x_values) - 1):\n",
    "        plt.plot(x_values[i:i+2], y_values[i:i+2], color=colors[i], linewidth=1.5)        \n",
    "    plt.title(f\"Plot for {row['File Name']} (Stress Level: {row['Stress Level']})\")\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.ylim(y_min, y_max)\n",
    "    plt.xlim(x_min, x_max)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    stress_level_folder = os.path.join(FFT_Plot_dir, str(row['Stress Level']))\n",
    "    os.makedirs(stress_level_folder, exist_ok=True)\n",
    "    file_name = row['File Name'].replace('.csv', '')\n",
    "    plot_filename = os.path.join(stress_level_folder, f\"{file_name}_plot.jpg\")\n",
    "    plt.savefig(plot_filename, dpi=300)\n",
    "    plt.close()\n",
    "print(\"Selesai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcea46d-5773-487b-8765-12968b092923",
   "metadata": {},
   "source": [
    "### DWT Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5257209-df22-45ef-a8b2-38935513dec2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = '6. Label/DWT_Labeled.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "os.makedirs(DWT_Plot_dir, exist_ok=True)\n",
    "global_y_min = df.iloc[:, 1:-1].values.min()\n",
    "global_y_max = df.iloc[:, 1:-1].values.max()\n",
    "print(\"Global Y-axis limits:\", global_y_min, global_y_max)\n",
    "for index, row in df.iterrows():\n",
    "    x_values = df.columns[1:-1].astype(float)\n",
    "    y_values = row.values[1:-1]\n",
    "    plt.plot(x_values, y_values, color='blue', linewidth=1.5)\n",
    "    plt.xlabel(\"DWT Coefficients\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.title(f\"DWT Data Plot for {row['File Name']} (Stress Level: {row['Stress Level']})\")\n",
    "    plt.ylim(global_y_min, global_y_max)\n",
    "    stress_level_folder = os.path.join(DWT_Plot_dir, str(row['Stress Level']))\n",
    "    os.makedirs(stress_level_folder, exist_ok=True)\n",
    "    file_name = row['File Name'].replace('.csv', '')\n",
    "    plot_filename = os.path.join(stress_level_folder, f\"{file_name}_plot.jpg\")\n",
    "    plt.savefig(plot_filename, dpi=300)\n",
    "    plt.close()\n",
    "print(\"Selesai\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efd0b7f",
   "metadata": {},
   "source": [
    "## Image to Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be542514-748a-4ace-949e-382e3d8b0955",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "def images_to_array(input_folder, target_size=(10, 4), num_samples=2):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for label in os.listdir(input_folder):\n",
    "        label_folder = os.path.join(input_folder, label)\n",
    "\n",
    "        if not os.path.isdir(label_folder):\n",
    "            continue\n",
    "\n",
    "        image_files = os.listdir(label_folder)\n",
    "        selected_images = random.sample(image_files, min(num_samples, len(image_files)))\n",
    "\n",
    "        for image_file in selected_images:\n",
    "            image_path = os.path.join(label_folder, image_file)\n",
    "            image = Image.open(image_path).convert('L')\n",
    "            image = image.resize(target_size)\n",
    "            image_array = np.array(image, dtype=np.uint8)\n",
    "\n",
    "            data.append(image_array)\n",
    "            labels.append(label)\n",
    "\n",
    "    return data, labels\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_folder = \"7.2. DWT_Plot\"\n",
    "\n",
    "    data, labels = images_to_array(input_folder)\n",
    "\n",
    "    for idx, (matrix, label) in enumerate(zip(data, labels)):\n",
    "        print(f\"Indeks: {idx}, Label: {label}\")\n",
    "        print(pd.DataFrame(matrix).to_string(index=False, header=[f\"Feature_{i+1}\" for i in range(matrix.shape[1])]))\n",
    "        print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
